[TOC]

## 1 任务

本工程旨在通过理解文本内容，实现数据内容智能发现与分级分类。具体来说，需要识别样本中的敏感数据，构建基于敏感数据本体的分级分类模型，判断数据所属的类别以及级别。
+ 利用远程监督技术，基于小样本构建文档分类分级样本库。
+ 结合当下先进的深度学习和机器学习技术，利用已构建的样本库，提取文本语义特征，构建泛化能力强且能自我学习的文档分类分级模型。


## 2 数据
本工程包含数据包括：
### 2.1 已标注数据(labeled_data.csv)
共7000篇文档，类别包含7类，分别为：财经、房产、家居、教育、科技、时尚、时政，每一类包含1000篇文档。
| 字段信息 | 数据类型 | 描述 |
| :-----: | :----: | :----: |
| id | String | 数据ID |
| class_label | String | 文本所属类别 |
| content | String | 文本内容 |

### 2.2 未标注数据(unlabeled_data.csv)
共33000篇文档，未给出具体类别。
| 字段信息 | 数据类型 | 描述 |
| :-----: | :----: | :----: |
| id | String | 数据ID |
| content | String | 文本内容 |

### 2.3 分类分级测试数据(test_data.csv)
共20000篇文档，包含10个类别:财经、房产、家居、教育、科技、时尚、时政、游戏、娱乐、体育。
| 字段信息 | 数据类型 | 描述 |
| :-----: | :----: | :----: |
| id | String | 数据ID |
| content | String | 文本内容 |

### 2.4 分级信息
| 文档类别 | 文档级别 |
| :-----: | :----: |
| 财经、时政 | 高风险 |
| 房产、科技 | 中风险 |
| 教育、时尚、游戏 | 低风险 |
| 家居、体育、娱乐 | 可公开 |


## 3 目录
+ files：该目录用于存放数据，受限于数据大小，若需获取数据，可与我联系。
+ lib：该目录用于存放albert, bert, xlnet等预训练模型，可在hugging face官网下载
+ model：该目录存放工程用到的工具函数，包括：
    + config.py：设置各项参数
    + model.py：设置模型结构
    + utils.py：工具函数
+ main.py：工程主程序


## 4 模型说明

### 4.1 特征工程
由于训练集文档只有7种类别，而实际预测的训练集会有10种，所以需要利用未标注数据创造伪训练集一并进行训练。
在main.py中，设置```is_psedu=True```可生成psedu_data.csv，包含未出现在训练集中的三种类别文档。

### 4.2 模型选择
本次实验共使用4种不同模型进行训练，分别是albert-tiny、roberta-tiny、bert-base、xlnet，模型选择可通过config.py中修改model_name参数，选择不同的模型路径实现。


## 5 实验结果
1. 若不使用特征工程，模型准确率仅为44%左右；使用特征工程后，不论哪种模型，准确率都在70%以上。
2. 同一模型下，增大batch_size，准确率会有进一步提升。
在内存允许范围内，采用最大batch_size后的模型效果如下所示。

| 模型类型 | 准确率 |
| :-----: | :----: |
| XLNet | 76.2% |
| Bert-base | 81.4% |
| Roberta-tiny | 71.1% |
| Albert-tiny | 75.0% |